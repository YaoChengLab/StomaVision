{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation for SAI dataset\n",
    "\n",
    "This file consists of script that \n",
    " 1. convert SAI dataset into Detectron2 compatible format\n",
    " 2. shuffle dataset into train, val and test.\n",
    "\n",
    "Note that dataset must organised in the standard data structure illustrated in the README.md."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, shutil\n",
    "\n",
    "\n",
    "def split_dataset(label_dicts: list, split_ratio: list) -> dict:\n",
    "    r\"\"\"\n",
    "    split dataset into three subsets: train, val and test.\n",
    "\n",
    "    Args:\n",
    "     - label_dicts (list): is the label dictionary. User must shuffle before split.\n",
    "     - split_ratio (list): this is a list consisting of the ratio between train, val, test.\n",
    "       e.g. split_ratio = [8,1,1] denotes train:val:test = 8:1:1\n",
    "    \"\"\"\n",
    "\n",
    "    # split dataset\n",
    "    train_num = int(len(label_dicts) * (split_ratio[0] / sum(split_ratio)))\n",
    "    val_num = int(len(label_dicts) * (split_ratio[1] / sum(split_ratio)))\n",
    "    test_num = int(len(label_dicts) * (split_ratio[2] / sum(split_ratio)))\n",
    "    print(f\"set [train:val:test] to [{train_num}:{val_num}:{test_num}]\")\n",
    "\n",
    "    # initialise variables\n",
    "    label_cat = {}\n",
    "    label_cat[\"train\"] = label_dicts[:train_num]\n",
    "    # When there is test set\n",
    "    if split_ratio[2] != 0:\n",
    "        label_cat[\"val\"] = label_dicts[train_num : train_num + val_num]\n",
    "        label_cat[\"test\"] = label_dicts[train_num + val_num :]\n",
    "    # Test set may consit of data cuz we use int(.) to convert length*ratio to index\n",
    "    # code below guarantees no data in test set.\n",
    "    else:\n",
    "        label_cat[\"val\"] = label_dicts[train_num:]\n",
    "        label_cat[\"test\"] = []\n",
    "\n",
    "    return label_cat\n",
    "\n",
    "\n",
    "def save_ext_dataset(dataset_name: str, data_path: str, label_cat: dict):\n",
    "    r\"\"\"\n",
    "    save dataset and label to its correponding folders.\n",
    "\n",
    "    Args:\n",
    "     - dataset_name (str): name of the dataset.\n",
    "     - dataset_path (str): path of the dataset.\n",
    "     - label_cat (dict): a dictionary consisting of the labels of train, val and test set. Get this with function split_dataset()\n",
    "    \"\"\"\n",
    "\n",
    "    # iterate through different subset.\n",
    "    for d in [\"train\", \"val\", \"test\"]:\n",
    "\n",
    "        # INITIALISATION for {d}\n",
    "        # set up output dir for {d}\n",
    "        sub_img_dir = os.path.join(data_path, dataset_name, \"images\", d)\n",
    "        shutil.rmtree(sub_img_dir, ignore_errors=True)\n",
    "        os.makedirs(sub_img_dir, exist_ok=True)\n",
    "\n",
    "        # set up label file for {d}\n",
    "        sub_label_filenames = os.path.join(\n",
    "            data_path, dataset_name, \"labels\", f\"labels_{d}.json\"\n",
    "        )\n",
    "        open(sub_label_filenames, \"w\").close()  # reset file\n",
    "\n",
    "        # CREATE CORRESPONDING SET for {d}\n",
    "        # construct label file\n",
    "        with open(sub_label_filenames, \"a\") as f:\n",
    "            f.write(\"[\")\n",
    "\n",
    "        # extract training and validation imgs and labels from /images and labels.json\n",
    "        for idx, v in enumerate(label_cat[d]):\n",
    "\n",
    "            # copy training set from images to /train\n",
    "            orig = os.path.join(\n",
    "                data_path,\n",
    "                dataset_name,\n",
    "                \"images\",\n",
    "                \"all\",\n",
    "                os.path.basename(v[\"file_name\"]),\n",
    "            )\n",
    "            dst = os.path.join(sub_img_dir, os.path.basename(v[\"file_name\"]))\n",
    "            shutil.copyfile(orig, dst)\n",
    "\n",
    "            # save dict to label_train.json\n",
    "            with open(sub_label_filenames, \"a\") as f:\n",
    "                json.dump(v, f)\n",
    "                if idx < len(label_cat[d]) - 1:  # do not add , at the end of the\n",
    "                    f.write(\",\")\n",
    "\n",
    "        with open(sub_label_filenames, \"a\") as f:\n",
    "            f.write(\"]\")\n",
    "            f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert, shuffle and split\n",
    "This script does:\n",
    "1. convert COCO labeling format to Detectron2 compatible\n",
    "2. shuffle and split dataset into train, val, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parsing data from ../2023-SAI-arabidopsis-42/labels/labels.json...\n",
      "Number of images loaded: 42\n",
      "processing......\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "8\n",
      "6\n",
      "4\n",
      "13\n",
      "4\n",
      "7\n",
      "8\n",
      "3\n",
      "10\n",
      "4\n",
      "6\n",
      "12\n",
      "4\n",
      "7\n",
      "6\n",
      "5\n",
      "3\n",
      "9\n",
      "5\n",
      "8\n",
      "10\n",
      "5\n",
      "8\n",
      "7\n",
      "9\n",
      "5\n",
      "6\n",
      "10\n",
      "9\n",
      "8\n",
      "4\n",
      "6\n",
      "9\n",
      "6\n",
      "10\n",
      "6\n",
      "10\n",
      "11\n",
      "set [train:val:test] to [33:8:0]\n",
      "processed data is saved to ../2023-SAI-arabidopsis-42\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "\n",
    "\"\"\"_SOURCE FORMAT\n",
    "Source dataset follow stantard coco format. It consists\n",
    "    \"images\": (a list of image object below)\n",
    "        \"file_name\": (string)\n",
    "        \"width\": (int)\n",
    "        \"height\": (int)\n",
    "        \"id\": (this is used to link with the annotations)\n",
    "    \"annotations\": (list of annotation object below) \n",
    "        \"bbox\": (a list consisting of four values)\n",
    "        \"area\": (int)\n",
    "        \"iscorwd\": (default set to 0)\n",
    "        \"category_id\": (this is used to link with the categories)\n",
    "        \"keypoints\": (a list of key points)\n",
    "        \"segmentations\": (a list of segmentation list)\n",
    "        \"num_keypoints\": (int)\n",
    "        \"image_id\": (this is used to link with the images)\n",
    "        \"id\": (this is the id of the annotation)\n",
    "    \"categories\": (list of category object below)\n",
    "        \"id\": (int, category id)\n",
    "        \"name\": (string, name of the category)\n",
    "\n",
    "See https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch/#coco-dataset-format for further instruction.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"_summary_\n",
    "TARGET FORMAT\n",
    "Target format is a list of dictionaries.\n",
    "Each dictionary consists of the following entry\n",
    "    \"file_name\": (string)\n",
    "    \"image_id\": (int)\n",
    "    \"height\": (int)\n",
    "    \"width\": (int)\n",
    "    \"annotations\": (list of annotations below)\n",
    "        \"bbox\": (a list consisting of four values)\n",
    "        \"bbox_mode\": (default set to 0)\n",
    "        \"segmentation\": (a list of segmentation list)\n",
    "        \"category_id\": (default set to 0)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dataset_dir = \"../../../google-drive/stomaVDP\"\n",
    "dataset_name = \"2023-SAI-arabidopsis-42\"\n",
    "seed_num = 28825252\n",
    "split_ratio = [8, 2, 0]  # The ratio stands for train:val:test\n",
    "\n",
    "img_dir = os.path.join(dataset_dir, dataset_name, \"images\", \"all\")\n",
    "label_input = os.path.join(dataset_dir, dataset_name, \"labels\", \"labels.json\")\n",
    "label_output_dir = os.path.join(dataset_dir, dataset_name, \"labels\")\n",
    "\n",
    "print(f\"Start parsing data from {label_input}...\")\n",
    "\n",
    "# Load Coco format JSON file\n",
    "source_annotations = None\n",
    "with open(label_input) as f:\n",
    "    source_annotations = json.load(f)\n",
    "\n",
    "img_num = len(source_annotations[\"images\"])\n",
    "print(f\"Number of images loaded: {img_num}\")\n",
    "\n",
    "# init label list\n",
    "label_dicts = []\n",
    "\n",
    "print(\"processing......\")\n",
    "for source_img in source_annotations[\"images\"]:\n",
    "    # init image dict\n",
    "    target_img = {}\n",
    "\n",
    "    # set basic info\n",
    "    target_img[\"file_name\"] = source_img[\"file_name\"]\n",
    "    target_img[\"image_id\"] = source_img[\"id\"]\n",
    "    target_img[\"height\"] = source_img[\"height\"]\n",
    "    target_img[\"width\"] = source_img[\"width\"]\n",
    "\n",
    "    # init annotation list\n",
    "    target_img[\"annotations\"] = []\n",
    "\n",
    "    for source_anno in source_annotations[\"annotations\"]:\n",
    "        # init annotation dict\n",
    "        target_anno = {}\n",
    "\n",
    "        if (\n",
    "            source_img[\"id\"] == source_anno[\"image_id\"]\n",
    "        ):  # the annotation belongs to the image\n",
    "            # set annotation info\n",
    "            target_anno[\"bbox\"] = source_anno[\"bbox\"]\n",
    "            target_anno[\"bbox_mode\"] = 0  # this value is by default\n",
    "            target_anno[\"category_id\"] = (\n",
    "                0  # this value is by default as we only have one class\n",
    "            )\n",
    "\n",
    "            # init segmentation list\n",
    "            target_anno[\"segmentation\"] = []\n",
    "\n",
    "            for seg in source_anno[\"segmentation\"]:\n",
    "                # set segmentation info\n",
    "                target_anno[\"segmentation\"].append(seg)\n",
    "\n",
    "            # append annotation to img dict\n",
    "            target_img[\"annotations\"].append(target_anno)\n",
    "\n",
    "    print(len(target_img[\"annotations\"]))\n",
    "    # append img to label list\n",
    "    label_dicts.append(target_img)\n",
    "\n",
    "# Shuffle, split and save datas and labels\n",
    "random.seed(seed_num)\n",
    "random.shuffle(label_dicts)\n",
    "label_cat = split_dataset(label_dicts, split_ratio)\n",
    "\n",
    "# Save to files\n",
    "save_ext_dataset(dataset_name, dataset_dir, label_cat)\n",
    "print(f\"processed data is saved to {os.path.join(dataset_dir, dataset_name)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abrc-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
